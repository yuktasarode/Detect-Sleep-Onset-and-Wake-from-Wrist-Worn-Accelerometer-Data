{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":53666,"databundleVersionId":6589269,"sourceType":"competition"}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Exploring and Visualizing CMI Sleep Dataset \nIn this notebook I perform an exploratory analaysis and visualization of the Child Mind Institute sleep monitoring dataset, as part of the [Detect Sleep States](https://www.kaggle.com/competitions/child-mind-institute-detect-sleep-states/overview) competition.","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport polars as pl\nimport datetime \nfrom tqdm import tqdm\n\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go","metadata":{"execution":{"iopub.status.busy":"2023-11-20T00:27:39.782612Z","iopub.execute_input":"2023-11-20T00:27:39.783457Z","iopub.status.idle":"2023-11-20T00:27:41.151852Z","shell.execute_reply.started":"2023-11-20T00:27:39.783419Z","shell.execute_reply":"2023-11-20T00:27:41.150662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing data\nSince the time series dataset is very large, we will use [`polars`](https://www.pola.rs) in this notebook as opposed to the more conventional `pandas` library. We begin by importing the datasets and extracting the time data from the 'timestamp' field. Wherever possible we will cast our columns into efficient datatypes to save on memory.","metadata":{}},{"cell_type":"code","source":"# Importing data \ndt_transforms = [\n    pl.col('timestamp').str.to_datetime(), \n    (pl.col('timestamp').str.to_datetime().dt.year()-2000).cast(pl.UInt8).alias('year'), \n    pl.col('timestamp').str.to_datetime().dt.month().cast(pl.UInt8).alias('month'),\n    pl.col('timestamp').str.to_datetime().dt.day().cast(pl.UInt8).alias('day'), \n    pl.col('timestamp').str.to_datetime().dt.hour().cast(pl.UInt8).alias('hour')\n]\n\ndata_transforms = [\n    pl.col('anglez').cast(pl.Int8), # Casting anglez to 8 bit integer\n    (pl.col('enmo')*1000).cast(pl.UInt16), # Convert enmo to 16 bit uint\n]\n\ntrain_series = pl.scan_parquet('/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet').with_columns(\n    dt_transforms + data_transforms\n    )\n\ntrain_events = pl.read_csv('/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv').with_columns(\n    dt_transforms\n    )\n\ntest_series = pl.scan_parquet('/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet').with_columns(\n    dt_transforms + data_transforms\n    )\n\n# Getting series ids as a list for convenience\nseries_ids = train_events['series_id'].unique(maintain_order=True).to_list()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T00:27:41.153695Z","iopub.execute_input":"2023-11-20T00:27:41.154231Z","iopub.status.idle":"2023-11-20T00:27:41.464649Z","shell.execute_reply.started":"2023-11-20T00:27:41.154190Z","shell.execute_reply":"2023-11-20T00:27:41.463743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing time series\nLet's create a function to visualize given series in a way which displays our two main datapoints, `anglez` and `enmo`, along with the onset and wakeup events which we would like to predict - or equivalently, combining the two, the sleeping periods vs. the wakeful periods of the time series. Our visualization should also be able to handle missing data by marking days with missing values.\n\nTo begin, let's find out whether the number of onset events always equals the number of wakeup events. In principle these numbers should always be the same.","metadata":{}},{"cell_type":"code","source":"onset_counts = train_events.filter(pl.col('event')=='onset').group_by('series_id').count().sort('series_id')['count']\nwakeup_counts = train_events.filter(pl.col('event')=='wakeup').group_by('series_id').count().sort('series_id')['count']\n\ncounts = pl.DataFrame({'series_id':sorted(series_ids), 'onset_counts':onset_counts, 'wakeup_counts':wakeup_counts})\ncount_mismatches = counts.filter(counts['onset_counts'] != counts['wakeup_counts'])\n\nprint(f'Series where the number of onsets is not the same as the number of wakeups: {count_mismatches.shape[0]}')","metadata":{"execution":{"iopub.status.busy":"2023-11-20T00:27:41.466326Z","iopub.execute_input":"2023-11-20T00:27:41.466768Z","iopub.status.idle":"2023-11-20T00:27:41.501298Z","shell.execute_reply.started":"2023-11-20T00:27:41.466729Z","shell.execute_reply":"2023-11-20T00:27:41.500483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So there are four series where there is a mismatch. Let's remove these from our training set.","metadata":{}},{"cell_type":"code","source":"train_series = train_series.filter(~pl.col('series_id').is_in(count_mismatches['series_id']))\ntrain_events = train_events.filter(~pl.col('series_id').is_in(count_mismatches['series_id']))\n\n# Updating series_ids list\nseries_ids = train_events.drop_nulls()['series_id'].unique(maintain_order=True).to_list()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T00:27:41.503559Z","iopub.execute_input":"2023-11-20T00:27:41.504144Z","iopub.status.idle":"2023-11-20T00:27:41.522539Z","shell.execute_reply.started":"2023-11-20T00:27:41.504111Z","shell.execute_reply":"2023-11-20T00:27:41.521266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We also note the presence of missing labels in some of the series. That is, for some series there are days in which no onsets or wakeups are recorded, even though the time series data indicate periods where the participant likely was sleeping. Let's see how frequently this appears in our data. ","metadata":{}},{"cell_type":"code","source":"missing_data = train_events.group_by('series_id', maintain_order=True).agg(pl.col('step').map_elements(lambda x: x.is_null().any()).alias('MissingValues'))\nprint(f\"Series with missing data: {missing_data['MissingValues'].sum()}/{train_events['series_id'].n_unique()}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-20T00:27:41.523702Z","iopub.execute_input":"2023-11-20T00:27:41.524397Z","iopub.status.idle":"2023-11-20T00:27:41.565886Z","shell.execute_reply.started":"2023-11-20T00:27:41.524357Z","shell.execute_reply":"2023-11-20T00:27:41.564665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Unfortunately a large majority of series contain days with missing data. We will take this into consideration when training our model.","metadata":{}},{"cell_type":"markdown","source":"Now that we can be certain that the onsets and wakeup numbers match, we can define a plotting function that will display our two primary datapoints - anglez and enmo - on a time series for a given series_id, with the sleep stages highlighted. For completeness, we will also flag any days where there are missing or null values. ","metadata":{}},{"cell_type":"code","source":"def getdata(i, every=1) : \n    '''\n    Get data for a given sample series. \n    '''\n    \n    idx = series_ids[i] if type(i) == int else i\n    series = train_series.filter((pl.col('series_id') == idx) & (pl.col('step') % every == 0)).collect()\n    events = train_events.filter(pl.col('series_id') == idx)\n    \n    return idx, series, events\n\ndef plotdata(idx, series, events) :\n    '''\n    Plots a time series of anglez and enmo for the i-th series, using a \n    given frequency of samples, with wakeup and onset events marked. \n    every=1 uses every sample at 5 minute intervals, and every=12 gives \n    minute-to-minute time series. \n    '''\n    \n    fig = make_subplots(specs=[[{'secondary_y': True}]])\n    \n    # Plotting time series data\n    fig.add_trace(go.Scatter(x=series['timestamp'], y=series['anglez'], mode='lines', name='anglez'), secondary_y=False)\n    fig.add_trace(go.Scatter(x=series['timestamp'], y=series['enmo'], mode='lines', name='enmo'), secondary_y=True)\n    \n    # Plotting sleeping periods\n    onsets = events.filter((pl.col('event') == 'onset') & (pl.col('timestamp') != None))['timestamp'].to_list()\n    wakeups = events.filter((pl.col('event') == 'wakeup') & (pl.col('timestamp') != None))['timestamp'].to_list()\n    for onset, wakeup in zip(onsets, wakeups) :\n        fig.add_vrect(\n            x0=onset, x1=wakeup,\n            fillcolor='gray', opacity=0.2,\n            layer='below', line_width=0\n        )\n        \n    # Add dummy trace for the legend\n    fig.add_trace(go.Scatter(\n        x=[None],\n        y=[None],\n        mode='lines',\n        line=dict(color='gray', width=0),\n        fill='tozeroy',\n        fillcolor='gray',\n        opacity=0.2,\n        name=\"Sleeping periods\"\n    ))\n        \n    # Plotting days with missing data\n    start_date = events['timestamp'].min().replace(hour=0, minute=0, second=0, microsecond=0)\n    null_nights = events.filter(pl.col('step').is_null())['night'].unique().to_list()\n    for n in null_nights : \n        fig.add_vrect(\n            x0=start_date + datetime.timedelta(days=n-1), x1=start_date + datetime.timedelta(days=n),\n            fillcolor='violet', opacity=0.2,\n            layer='below', line_width=0\n        )\n    \n    # Add dummy trace for the legend\n    fig.add_trace(go.Scatter(\n        x=[None],\n        y=[None],\n        mode='lines',\n        line=dict(color='violet', width=0),\n        fill='tozeroy',\n        fillcolor='violet',\n        opacity=0.2,\n        name=\"Missing data\"\n    ))\n        \n    fig.update_layout(\n        title_text=f\"Accelerometer Data<br><sub>ID: {idx}</sub>\", \n        #template = 'ggplot2',\n        xaxis=dict(showgrid=False), yaxis=dict(showgrid=False), yaxis2=dict(showgrid=False)\n    )\n    \n    fig.show()\n    \n# data = getdata(10)\n\n# plotdata(*data)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T00:27:41.567096Z","iopub.execute_input":"2023-11-20T00:27:41.567458Z","iopub.status.idle":"2023-11-20T00:27:41.584476Z","shell.execute_reply.started":"2023-11-20T00:27:41.567428Z","shell.execute_reply":"2023-11-20T00:27:41.583218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"After plotting a few series samples, we can see some very clear patterns that tend to distinguish sleeping periods from wakeful periods. \n- During wakeful periods `anglez` varies constantly, rarely ever staying at the same value for consecutive measurements. During sleeping periods there tend to be periods of low to zero variability in `anglez` where the person will change positions and then remain there for many consecutive measurements. \n- During wakeful periods `enmo` also has much higher variability and reaches much greater values, while during sleeping periods `enmo` values stay very close to 0.\n- Days with missing data tend to have much smaller variations in `anglez`, as well as `enmo`. \n\n","metadata":{}},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"Let's start by looking at the series without any null values to look for features correlated with sleep/wakefullness, without being impacted by missing data.","metadata":{}},{"cell_type":"code","source":"i = 0\n\nfull_data_ids = missing_data.filter(pl.col('MissingValues')==False)['series_id'].to_list()\nidx, series, events = getdata(full_data_ids[i])\nplotdata(idx, series, events)\n\nonsets = events.filter((pl.col('event') == 'onset') & (pl.col('timestamp') != None))['timestamp'].to_list()\nwakeups = events.filter((pl.col('event') == 'wakeup') & (pl.col('timestamp') != None))['timestamp'].to_list()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T00:27:41.586040Z","iopub.execute_input":"2023-11-20T00:27:41.587139Z","iopub.status.idle":"2023-11-20T00:27:54.896629Z","shell.execute_reply.started":"2023-11-20T00:27:41.587084Z","shell.execute_reply":"2023-11-20T00:27:54.894828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's put together some features to see if we can find any that strongly correlate with sleeping phases. ","metadata":{}},{"cell_type":"code","source":"features = [sum([(onset <= pl.col('timestamp')) & (pl.col('timestamp') <= wakeup) for onset, wakeup in zip(onsets, wakeups)]).alias('asleep')]\nfeature_cols = ['asleep']\n\nrolling_durs = [1, 30, 60*3] # Rolling aggregate durations, in minutes\n\nfor var in ['anglez', 'enmo'] :\n    features += [pl.col(var).alias(var), \n                 pl.col(var).diff().fill_null(0).abs().alias(f'{var}_1v')\n                ]\n    feature_cols += [var, f'{var}_1v']\n    \n    # Rolling aggregates\n    for dur in rolling_durs :\n        features += [\n            pl.col(var).rolling_mean(dur * 12, center=True, min_periods=1).alias(f'{var}_{dur}m_mean'), # Rolling mean\n           \n            \n            # Rolling total variations\n            pl.col(var).diff().fill_null(0).abs().rolling_mean(dur * 12, center=True, min_periods=1).alias(f'{var}_1v_{dur}m_mean'),\n            \n        ]\n\n        feature_cols += [\n            f'{var}_{dur}m_mean', f'{var}_1v_{dur}m_mean'\n        ]\n        \n# Lets also include enmo x anglez features\nfeatures += [\n    (pl.col('anglez') * pl.col('enmo')).alias('anglez.enmo'), \n    (pl.col('anglez') * pl.col('enmo')).alias('anglez.enmo').diff().fill_null(0).abs().alias('anglez.enmo_1v')\n]\n\nfeature_cols += [\n    'anglez.enmo', 'anglez.enmo_1v'\n]\n\nfor dur in rolling_durs :\n    features += [\n        (pl.col('anglez') * pl.col('enmo')).rolling_mean(dur * 12, center=True, min_periods=1).alias(f'anglez.enmo_{dur}m_mean'), # Rolling mean\n        \n\n        # Rolling total variations\n        (pl.col('anglez') * pl.col('enmo')).diff().fill_null(0).abs().rolling_mean(dur * 12, center=True, min_periods=1).alias(f'anglez.enmo_1v_{dur}m_mean'),\n        \n    ]\n\n    feature_cols += [\n        f'anglez.enmo_{dur}m_mean', f'anglez.enmo_1v_{dur}m_mean'\n    ]\n\ncorr_df = series.with_columns(features)[feature_cols].corr()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T00:27:54.898830Z","iopub.execute_input":"2023-11-20T00:27:54.899408Z","iopub.status.idle":"2023-11-20T00:27:55.283835Z","shell.execute_reply.started":"2023-11-20T00:27:54.899372Z","shell.execute_reply":"2023-11-20T00:27:55.282594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = series.with_columns(features)","metadata":{"execution":{"iopub.status.busy":"2023-11-20T00:27:55.285436Z","iopub.execute_input":"2023-11-20T00:27:55.285782Z","iopub.status.idle":"2023-11-20T00:27:55.481784Z","shell.execute_reply.started":"2023-11-20T00:27:55.285750Z","shell.execute_reply":"2023-11-20T00:27:55.480934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(r'Z-Angle \\times ENMO')","metadata":{"execution":{"iopub.status.busy":"2023-11-20T00:27:55.484560Z","iopub.execute_input":"2023-11-20T00:27:55.484883Z","iopub.status.idle":"2023-11-20T00:27:55.489709Z","shell.execute_reply.started":"2023-11-20T00:27:55.484856Z","shell.execute_reply":"2023-11-20T00:27:55.488797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from plotly.subplots import make_subplots\n\nN = (len(feature_cols)-1)//3\n\n#fig = make_subplots(cols=1, rows=3)\nvariables = ['Z-Angle', 'ENMO']\nfor c in range(2) :\n    fig = go.Figure()\n    cols = feature_cols[:1] + feature_cols[c*N + 1:(c+1)*N + 1]\n    fig.add_trace(\n        go.Heatmap(\n            x = cols,\n            y = cols,\n            z = df[cols].corr(),\n            text=df[cols].corr(),\n            texttemplate='%{text:.2f}',\n            zmin=-1,zmax=1\n        )\n    )\n    fig.update_layout(title_text=f\"{variables[c]} correlation map<br><sub>ID: {idx}<sub>\")\n    fig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T00:27:55.490959Z","iopub.execute_input":"2023-11-20T00:27:55.492072Z","iopub.status.idle":"2023-11-20T00:27:55.708365Z","shell.execute_reply.started":"2023-11-20T00:27:55.492034Z","shell.execute_reply":"2023-11-20T00:27:55.707250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# features = [sum([(onset <= pl.col('timestamp')) & (pl.col('timestamp') <= wakeup) for onset, wakeup in zip(onsets, wakeups)]).alias('asleep')]\n# feature_cols = ['asleep']\n\n# rolling_durs = [1, 30, 60*3] # Rolling aggregate durations, in minutes\n\n# for var in ['anglez', 'enmo'] :\n#     features += [pl.col(var).alias(var), pl.col(var).diff().abs().alias(f'{var}_1v')]\n#     feature_cols += [var, f'{var}_1v']\n    \n#     # Rolling aggregates\n#     for dur in rolling_durs :\n#         features += [\n#             pl.col(var).rolling_mean(dur * 12, center=True, min_periods=1).alias(f'{var}_{dur}m_mean'), # Rolling mean\n           \n#             # Rolling total variations\n#             pl.col(var).diff().abs().rolling_mean(dur * 12, center=True, min_periods=1).alias(f'{var}_1v_{dur}m_mean'),\n#                 ]\n\n#         feature_cols += [\n#             f'{var}_{dur}m_mean', f'{var}_1v_{dur}m_mean'\n#         ]\n        \n# # Lets also include enmo x anglez features\n# features += [\n#     (pl.col('anglez') * pl.col('enmo')).alias('anglez.enmo'), \n#     (pl.col('anglez') * pl.col('enmo')).alias('anglez.enmo').diff().abs().alias('anglez.enmo_1v')\n# ]\n\n# feature_cols += [\n#     'anglez.enmo', 'anglez.enmo_1v'\n# ]\n\n# for dur in rolling_durs :\n#     features += [\n#         (pl.col('anglez') * pl.col('enmo')).rolling_mean(dur * 12, center=True, min_periods=1).alias(f'anglez.enmo_{dur}m_mean'), # Rolling mean\n       \n#         # Rolling total variations\n#         (pl.col('anglez') * pl.col('enmo')).diff().abs().rolling_mean(dur * 12, center=True, min_periods=1).alias(f'anglez.enmo_1v_{dur}m_mean')\n#           ]\n\n#     feature_cols += [\n#         f'anglez.enmo_{dur}m_mean', f'anglez.enmo_1v_{dur}m_mean'\n#     ]\n\n# corr_df = series.with_columns(features)\n\n\n# fig = go.Figure()\n# fig.add_trace(\n#     go.Heatmap(\n#         x = cols,\n#         y = cols,\n#         z = corr_df[cols].drop_nulls().corr(),\n#         text=corr_df[cols].drop_nulls().corr(),\n#         texttemplate='%{text:.2f}'\n#     )\n# )\n# fig.update_layout(title_text=f\"Feature correlation map<br><sub>ID: {idx}<sub>\")\n# fig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T00:27:55.711358Z","iopub.execute_input":"2023-11-20T00:27:55.711950Z","iopub.status.idle":"2023-11-20T00:27:55.719237Z","shell.execute_reply.started":"2023-11-20T00:27:55.711908Z","shell.execute_reply":"2023-11-20T00:27:55.717880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some observations: \n- The longer 30 minute rolling windows outperformed both the minute rolling window and the individual datapoints by a wide margin.\n- The feature correlated most closely with sleeping is the 30 minute rolling average of the first order variation of anglez, with a 75% negative correlation.\n- Both the enmo 30 minute rolling average and the enmo 30 minute rolling first order variation offered strong negative correlations. \n- The rolling 30 minute multiplicative combitionation of anglez and enmo offered a strong positive correlation as well. ","metadata":{}},{"cell_type":"markdown","source":"Let's see how these four correlations hold up across the other sample series with full data.","metadata":{}},{"cell_type":"code","source":"cols = ['asleep', 'anglez_1v_r30', 'enmo_1v_r30', 'enmo_r30', 'anglezxenmo_r30', 'enmo_1v_30m_mean', 'anglez_1v_30m_mean']\nsleep_corr = pl.DataFrame()\n\nfor idx in tqdm(full_data_ids) : \n    idx, series, events = getdata(idx)\n\n    onsets = events.filter((pl.col('event') == 'onset') & (pl.col('timestamp') != None))['timestamp'].to_list()\n    wakeups = events.filter((pl.col('event') == 'wakeup') & (pl.col('timestamp') != None))['timestamp'].to_list()\n    \n    features = series.with_columns(\n        sum([(onset <= pl.col('timestamp')) & (pl.col('timestamp') <= wakeup) for onset, wakeup in zip(onsets, wakeups)]).alias('asleep'), \n        pl.col('enmo').rolling_mean(12*30, center=True).alias('enmo_r30'), # Rolling mean of enmo for 30 minutes\n        (pl.col('enmo') * pl.col('anglez')).rolling_mean(12*30, center=True).alias('anglezxenmo_r30'), # Rolling mean of anglez times enmo for 30 minutes\n        (pl.col('anglez').shift(-1) - pl.col('anglez')).abs().rolling_mean(12*30, center=True).alias('anglez_1v_r30'), # 1st order variation of anglez for 30 min\n        (pl.col('enmo').shift(-1) - pl.col('enmo')).abs().rolling_mean(12*30, center=True).alias('enmo_1v_r30') # First order variation of enmo for 30 minutes\n    )\n    \n    # Calculate 'enmo_1v' and 'anglez_1v' columns before using them\n    features = features.with_columns(\n        pl.col('enmo').diff().abs().alias('enmo_1v'),\n        pl.col('anglez').diff().abs().alias('anglez_1v')\n    )\n    \n    for dur in [30]:  # You can add other durations if needed\n        features = features.with_columns(\n            pl.col('enmo_1v').rolling_mean(dur * 12, center=True, min_periods=1).alias(f'enmo_1v_{dur}m_mean'),\n            pl.col('anglez_1v').rolling_mean(dur * 12, center=True, min_periods=1).alias(f'anglez_1v_{dur}m_mean')\n        )\n    \n    corr_df = features\n    \n    sleep_corr = sleep_corr.vstack(corr_df[cols].drop_nulls().corr()[0].drop('asleep').with_columns(pl.lit(idx).alias('ID')))\n","metadata":{"execution":{"iopub.status.busy":"2023-11-20T00:27:55.720471Z","iopub.execute_input":"2023-11-20T00:27:55.720773Z","iopub.status.idle":"2023-11-20T00:33:44.912188Z","shell.execute_reply.started":"2023-11-20T00:27:55.720742Z","shell.execute_reply":"2023-11-20T00:33:44.911432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_cols = [col for col in cols if col != 'asleep']\n\nfig = go.Figure()\nfor col in plot_cols : \n    fig.add_trace(go.Violin(y=sleep_corr[col],\n                            name=col,\n                            box_visible=True,\n                            meanline_visible=True))\n    \nfig.update_layout(title_text='Feature correlation with sleep across all full-data time series')\n    \nfig.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-20T00:33:44.913532Z","iopub.execute_input":"2023-11-20T00:33:44.914087Z","iopub.status.idle":"2023-11-20T00:33:44.956926Z","shell.execute_reply.started":"2023-11-20T00:33:44.914047Z","shell.execute_reply":"2023-11-20T00:33:44.955872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Our rolling average anglez $\\times$ enmo feature's correlation with sleep does not appear to be robust across the other time series, so we will discard it and move forward with the remaining three features, whose correlations do appear to be robust. ","metadata":{}},{"cell_type":"markdown","source":"### Exploiting periodicity\nNOTE: I'll come back to this later. ","metadata":{}},{"cell_type":"code","source":"px.histogram(train_events, x='hour', color='event', opacity=0.5, barmode='overlay')","metadata":{"execution":{"iopub.status.busy":"2023-11-20T00:33:44.960251Z","iopub.execute_input":"2023-11-20T00:33:44.960850Z","iopub.status.idle":"2023-11-20T00:33:46.298184Z","shell.execute_reply.started":"2023-11-20T00:33:44.960818Z","shell.execute_reply":"2023-11-20T00:33:46.297063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Random Forest Model\nThis section has been moved to my [Feature Engineering and Random Forest Prediction](https://www.kaggle.com/code/lccburk/feature-engineering-and-random-forest-prediction) notebook.","metadata":{}}]}